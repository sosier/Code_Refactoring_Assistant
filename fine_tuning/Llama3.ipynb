{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3 Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d9bd1ec4ad4b7badd8ebd57b813beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\n",
    "    \"mps\" if torch.backends.mps.is_available()\n",
    "    else (\n",
    "        \"cuda\" if torch.cuda.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    ")\n",
    "MODELS_PATH = os.getenv(\"HOME\") + \"/models/fine_tuned/llama3/\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    # NOTE: BFloat16 is not supported on MPS, so using Float16\n",
    "    # model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    "    device=DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_num = 1\n",
    "pipeline.model.load_state_dict(torch.load(MODELS_PATH + f\"fine_tuned_llama3_smaller_LR_after_{epoch_num}_epoch.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    system_prompt,\n",
    "    user_prompt,\n",
    "    max_new_tokens=1000,\n",
    "    do_sample=False,\n",
    "    temperature=1.0,\n",
    "    top_p=1.0\n",
    "):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        # Set pad_token_id so as not to get warning every time:\n",
    "        pad_token_id=pipeline.tokenizer.eos_token_id\n",
    "    )\n",
    "    return outputs[0][\"generated_text\"][len(prompt):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrr, shiver me timbers! Me name be Captain Chat, the scurviest pirate chatbot to ever sail the Seven Seas o' the Interwebs! I be here to swab yer decks with me witty banter and me treasure trove o' pirate knowledge. So hoist the colors, me hearty, and let's set sail fer a swashbucklin' good time!\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a pirate chatbot who always responds in pirate speak!\"\n",
    "user_prompt = \"Who are you?\"\n",
    "\n",
    "result = generate(\n",
    "    system_prompt,\n",
    "    user_prompt,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "result = generate(\n",
    "    system_prompt,\n",
    "    user_prompt,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "result2 = generate(\n",
    "    system_prompt,\n",
    "    user_prompt,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "print(result == result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Arrrr, me hearty! Me name be Captain Chat, the scurviest pirate chatbot to ever sail the Seven Seas o' the Interwebs! Me and me trusty crew o' code have been plunderin' the riches o' knowledge and bringin' 'em back to ye, me matey! So hoist the colors, me hearty, and let's set sail fer a swashbucklin' adventure o' learnin' and fun!\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# Expects this file and eval.py to be in the same folder:\n",
    "from eval import DATA, evaluate, bulk_evaluate\n",
    "\n",
    "mbpp = DATA[\"mbpp\"]  # train, validation, and test\n",
    "humaneval = DATA[\"openai_humaneval\"]  # test only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = \"./results/\"\n",
    "\n",
    "def save_pickle(object, to):\n",
    "    with open(to, \"wb\") as f:\n",
    "        pickle.dump(object, f)\n",
    "    \n",
    "def load_pickle(from_):\n",
    "    with open(from_, \"rb\") as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are the world's best AI coding assistant. In particular, you are exceptionally skilled at refactoring Python programs to be readable, efficient, and maintainable.\n",
    "\n",
    "For the interaction that follows, refactor the Python code provided by the user to be more readable, efficient, and maintainable using the following guidelines:\n",
    " - The given program is correct but needs improvement\n",
    " - DO NOT change the name of the program\n",
    " - DO NOT change the input or output behavior of the program (e.g. number of inputs / outputs, input / output types, etc.)\n",
    " - Put your response in a markdown code block\n",
    " - Respond with only the code block\n",
    " - Don't explain the changes made\n",
    " - If you use any packages (e.g. `os`, `re`, `sys`), don't forget to import them\n",
    "\n",
    "Again, do not change the name of the function in any way!\n",
    "\"\"\".strip()\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "```python\n",
    "{code}\n",
    "```\n",
    "\"\"\".strip()\n",
    "\n",
    "def refactor(code, system_prompt=SYSTEM_PROMPT, **kwargs):\n",
    "    return generate(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=USER_PROMPT.format(code=code),\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "def extract_from_code_block(raw_generation):\n",
    "    # assert raw_generation.startswith(\"```\")\n",
    "    # assert raw_generation.endswith(\"```\")\n",
    "\n",
    "    # # Simply remove first and last line\n",
    "    # return \"\\n\".join(raw_generation.split(\"\\n\")[1:-1])\n",
    "\n",
    "    # Remove ```s:\n",
    "    return raw_generation.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HumanEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_solutions = [\n",
    "    task[\"prompt\"] + task[\"canonical_solution\"] for task in humaneval[\"test\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW GENERATION:\n",
      "```\n",
      "from typing import List\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    for elem1 in numbers:\n",
      "        for elem2 in numbers:\n",
      "            if elem1!= elem2 and abs(elem1 - elem2) < threshold:\n",
      "                return True\n",
      "\n",
      "    return False\n",
      "```\n",
      "--------------------------------------------------------------------------------\n",
      "GENERATION:\n",
      "from typing import List\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    for elem1 in numbers:\n",
      "        for elem2 in numbers:\n",
      "            if elem1!= elem2 and abs(elem1 - elem2) < threshold:\n",
      "                return True\n",
      "\n",
      "    return False\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "raw_generation = refactor(\n",
    "    canonical_solutions[i]\n",
    ")\n",
    "generation = extract_from_code_block(raw_generation)\n",
    "\n",
    "print(\"RAW GENERATION:\")\n",
    "print(raw_generation)\n",
    "print(\"-\" * 80)\n",
    "print(\"GENERATION:\")\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    for idx, elem in enumerate(numbers):\n",
      "        for idx2, elem2 in enumerate(numbers):\n",
      "            if idx != idx2:\n",
      "                distance = abs(elem - elem2)\n",
      "                if distance < threshold:\n",
      "                    return True\n",
      "\n",
      "    return False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(canonical_solutions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Running this cell will delete all your generations. Be sure you want to do this!\n",
    "all_generations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "# WARNNG: Slow step:\n",
    "i = len(all_generations)\n",
    "while i < len(canonical_solutions):\n",
    "    print(i)\n",
    "    raw_generation = refactor(canonical_solutions[i])\n",
    "    generation = extract_from_code_block(raw_generation)\n",
    "    all_generations.append(generation)\n",
    "    i += 1\n",
    "\n",
    "    # Every 10, Save to pickle just in case\n",
    "    if i % 10 == 0:\n",
    "        save_pickle(all_generations, RESULTS_PATH + \"openai_humaneval_test_llama3_0_shot_in_progress_generations.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending 164 jobs for execution...\n",
      "164 jobs sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 164 job results...\n",
      "Fetching 1/164...\n",
      "Fetching 2/164...\n",
      "Fetching 3/164...\n",
      "Fetching 4/164...\n",
      "Fetching 5/164...\n",
      "Fetching 6/164...\n",
      "Fetching 7/164...\n",
      "Fetching 8/164...\n",
      "Fetching 9/164...\n",
      "Fetching 10/164...\n",
      "Fetching 11/164...\n",
      "Fetching 12/164...\n",
      "Fetching 13/164...\n",
      "Fetching 14/164...\n",
      "Fetching 15/164...\n",
      "Fetching 16/164...\n",
      "Fetching 17/164...\n",
      "Fetching 18/164...\n",
      "Fetching 19/164...\n",
      "Fetching 20/164...\n",
      "Fetching 21/164...\n",
      "Fetching 22/164...\n",
      "Fetching 23/164...\n",
      "Fetching 24/164...\n",
      "Fetching 25/164...\n",
      "Fetching 26/164...\n",
      "Fetching 27/164...\n",
      "Fetching 28/164...\n",
      "Fetching 29/164...\n",
      "Fetching 30/164...\n",
      "Fetching 31/164...\n",
      "Fetching 32/164...\n",
      "Fetching 33/164...\n",
      "Fetching 34/164...\n",
      "Fetching 35/164...\n",
      "Fetching 36/164...\n",
      "Fetching 37/164...\n",
      "Fetching 38/164...\n",
      "Fetching 39/164...\n",
      "Fetching 40/164...\n",
      "Fetching 41/164...\n",
      "Fetching 42/164...\n",
      "Fetching 43/164...\n",
      "Fetching 44/164...\n",
      "Fetching 45/164...\n",
      "Fetching 46/164...\n",
      "Fetching 47/164...\n",
      "Fetching 48/164...\n",
      "Fetching 49/164...\n",
      "Fetching 50/164...\n",
      "Fetching 51/164...\n",
      "Fetching 52/164...\n",
      "Fetching 53/164...\n",
      "Fetching 54/164...\n",
      "Fetching 55/164...\n",
      "Fetching 56/164...\n",
      "Fetching 57/164...\n",
      "Fetching 58/164...\n",
      "Fetching 59/164...\n",
      "Fetching 60/164...\n",
      "Fetching 61/164...\n",
      "Fetching 62/164...\n",
      "Fetching 63/164...\n",
      "Fetching 64/164...\n",
      "Fetching 65/164...\n",
      "Fetching 66/164...\n",
      "Fetching 67/164...\n",
      "Fetching 68/164...\n",
      "Fetching 69/164...\n",
      "Fetching 70/164...\n",
      "Fetching 71/164...\n",
      "Fetching 72/164...\n",
      "Fetching 73/164...\n",
      "Fetching 74/164...\n",
      "Fetching 75/164...\n",
      "Fetching 76/164...\n",
      "Fetching 77/164...\n",
      "Fetching 78/164...\n",
      "Fetching 79/164...\n",
      "Fetching 80/164...\n",
      "Fetching 81/164...\n",
      "Fetching 82/164...\n",
      "Fetching 83/164...\n",
      "Fetching 84/164...\n",
      "Fetching 85/164...\n",
      "Fetching 86/164...\n",
      "Fetching 87/164...\n",
      "Fetching 88/164...\n",
      "Fetching 89/164...\n",
      "Fetching 90/164...\n",
      "Fetching 91/164...\n",
      "Fetching 92/164...\n",
      "Fetching 93/164...\n",
      "Fetching 94/164...\n",
      "Fetching 95/164...\n",
      "Fetching 96/164...\n",
      "Fetching 97/164...\n",
      "Fetching 98/164...\n",
      "Fetching 99/164...\n",
      "Fetching 100/164...\n",
      "Fetching 101/164...\n",
      "Fetching 102/164...\n",
      "Fetching 103/164...\n",
      "Fetching 104/164...\n",
      "Fetching 105/164...\n",
      "Fetching 106/164...\n",
      "Fetching 107/164...\n",
      "Fetching 108/164...\n",
      "Fetching 109/164...\n",
      "Fetching 110/164...\n",
      "Fetching 111/164...\n",
      "Fetching 112/164...\n",
      "Fetching 113/164...\n",
      "Fetching 114/164...\n",
      "Fetching 115/164...\n",
      "Fetching 116/164...\n",
      "Fetching 117/164...\n",
      "Fetching 118/164...\n",
      "Fetching 119/164...\n",
      "Fetching 120/164...\n",
      "Fetching 121/164...\n",
      "Fetching 122/164...\n",
      "Fetching 123/164...\n",
      "Fetching 124/164...\n",
      "Fetching 125/164...\n",
      "Fetching 126/164...\n",
      "Fetching 127/164...\n",
      "Fetching 128/164...\n",
      "Fetching 129/164...\n",
      "Fetching 130/164...\n",
      "Fetching 131/164...\n",
      "Fetching 132/164...\n",
      "Fetching 133/164...\n",
      "Fetching 134/164...\n",
      "Fetching 135/164...\n",
      "Fetching 136/164...\n",
      "Fetching 137/164...\n",
      "Fetching 138/164...\n",
      "Fetching 139/164...\n",
      "Fetching 140/164...\n",
      "Fetching 141/164...\n",
      "Fetching 142/164...\n",
      "Fetching 143/164...\n",
      "Fetching 144/164...\n",
      "Fetching 145/164...\n",
      "Fetching 146/164...\n",
      "Fetching 147/164...\n",
      "Fetching 148/164...\n",
      "Fetching 149/164...\n",
      "Fetching 150/164...\n",
      "Fetching 151/164...\n",
      "Fetching 152/164...\n",
      "Fetching 153/164...\n",
      "Fetching 154/164...\n",
      "Fetching 155/164...\n",
      "Fetching 156/164...\n",
      "Fetching 157/164...\n",
      "Fetching 158/164...\n",
      "Fetching 159/164...\n",
      "Fetching 160/164...\n",
      "Fetching 161/164...\n",
      "Fetching 162/164...\n",
      "Fetching 163/164...\n",
      "Fetching 164/164...\n",
      "164 job results fetched\n"
     ]
    }
   ],
   "source": [
    "execution_ids_backup = []\n",
    "execution_results_backup = []\n",
    "\n",
    "results = bulk_evaluate(\n",
    "    dataset=\"openai_humaneval\",\n",
    "    split=\"test\",\n",
    "    code=all_generations,\n",
    "    execution_ids_backup=execution_ids_backup,\n",
    "    execution_results_backup=execution_results_backup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>task_id</th>\n",
       "      <th>model</th>\n",
       "      <th>code</th>\n",
       "      <th>result</th>\n",
       "      <th>compiled</th>\n",
       "      <th>passed_tests</th>\n",
       "      <th>avg_test_time</th>\n",
       "      <th>loc</th>\n",
       "      <th>...</th>\n",
       "      <th>N2</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>length</th>\n",
       "      <th>calculated_length</th>\n",
       "      <th>volume</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>effort</th>\n",
       "      <th>time</th>\n",
       "      <th>bugs</th>\n",
       "      <th>MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "      <td>failed:</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.509775</td>\n",
       "      <td>39.863137</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>106.301699</td>\n",
       "      <td>5.905650</td>\n",
       "      <td>0.013288</td>\n",
       "      <td>94.062602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "      <td>passed</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.406372</td>\n",
       "      <td>59.794706</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>153.757815</td>\n",
       "      <td>8.542101</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>86.970176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>def truncate_number(number: float) -&gt; float:\\n...</td>\n",
       "      <td>passed</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.754888</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.377444</td>\n",
       "      <td>0.132080</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>65.110353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(oper...</td>\n",
       "      <td>passed</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.754888</td>\n",
       "      <td>13.931569</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>18.575425</td>\n",
       "      <td>1.031968</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>96.412688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>4</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "      <td>passed</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.509775</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>87.277819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>159</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>def eat(number, need, remaining):\\n    \"\"\"\\n  ...</td>\n",
       "      <td>passed</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.509775</td>\n",
       "      <td>31.019550</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>124.078200</td>\n",
       "      <td>6.893233</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>55.822181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>160</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>def do_algebra(operator, operand):\\n    \"\"\"\\n ...</td>\n",
       "      <td>passed</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>57.058650</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>42.793988</td>\n",
       "      <td>2.377444</td>\n",
       "      <td>0.019020</td>\n",
       "      <td>45.813793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>161</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>def solve(s):\\n    \"\"\"You are given a string s...</td>\n",
       "      <td>failed:</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>96.882486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>162</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>def string_to_md5(text):\\n    \"\"\"\\n    Given a...</td>\n",
       "      <td>passed</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>163</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_1_epoch</td>\n",
       "      <td>def generate_integers(a, b):\\n    \"\"\"\\n    Giv...</td>\n",
       "      <td>passed</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.264663</td>\n",
       "      <td>28.529325</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>42.793988</td>\n",
       "      <td>2.377444</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>80.289730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset split  task_id  \\\n",
       "0    openai_humaneval  test        0   \n",
       "1    openai_humaneval  test        1   \n",
       "2    openai_humaneval  test        2   \n",
       "3    openai_humaneval  test        3   \n",
       "4    openai_humaneval  test        4   \n",
       "..                ...   ...      ...   \n",
       "159  openai_humaneval  test      159   \n",
       "160  openai_humaneval  test      160   \n",
       "161  openai_humaneval  test      161   \n",
       "162  openai_humaneval  test      162   \n",
       "163  openai_humaneval  test      163   \n",
       "\n",
       "                                          model  \\\n",
       "0    llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "1    llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "2    llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "3    llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "4    llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "..                                          ...   \n",
       "159  llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "160  llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "161  llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "162  llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "163  llama3_0_shot_finetuned_smaller_LR_1_epoch   \n",
       "\n",
       "                                                  code    result  compiled  \\\n",
       "0    from typing import List\\n\\ndef has_close_eleme...  failed:       True   \n",
       "1    from typing import List\\n\\ndef separate_paren_...    passed      True   \n",
       "2    def truncate_number(number: float) -> float:\\n...    passed      True   \n",
       "3    from typing import List\\n\\ndef below_zero(oper...    passed      True   \n",
       "4    from typing import List\\n\\ndef mean_absolute_d...    passed      True   \n",
       "..                                                 ...       ...       ...   \n",
       "159  def eat(number, need, remaining):\\n    \"\"\"\\n  ...    passed      True   \n",
       "160  def do_algebra(operator, operand):\\n    \"\"\"\\n ...    passed      True   \n",
       "161  def solve(s):\\n    \"\"\"You are given a string s...  failed:       True   \n",
       "162  def string_to_md5(text):\\n    \"\"\"\\n    Given a...    passed      True   \n",
       "163  def generate_integers(a, b):\\n    \"\"\"\\n    Giv...    passed      True   \n",
       "\n",
       "     passed_tests  avg_test_time   loc  ...    N2  vocabulary  length  \\\n",
       "0           False            NaN  16.0  ...   8.0        10.0    12.0   \n",
       "1            True       0.000088  29.0  ...  12.0        10.0    18.0   \n",
       "2            True       0.000063  10.0  ...   2.0         3.0     3.0   \n",
       "3            True       0.000132  19.0  ...   4.0         5.0     6.0   \n",
       "4            True       0.000095  14.0  ...   6.0         8.0     9.0   \n",
       "..            ...            ...   ...  ...   ...         ...     ...   \n",
       "159          True       0.000123  36.0  ...   8.0         6.0    12.0   \n",
       "160          True       0.000117  29.0  ...  12.0         9.0    18.0   \n",
       "161         False            NaN  18.0  ...   1.0         2.0     2.0   \n",
       "162          True       0.000061  11.0  ...   1.0         2.0     2.0   \n",
       "163          True       0.000102  14.0  ...   6.0         9.0     9.0   \n",
       "\n",
       "     calculated_length     volume  difficulty      effort      time      bugs  \\\n",
       "0            23.509775  39.863137    2.666667  106.301699  5.905650  0.013288   \n",
       "1            24.406372  59.794706    2.571429  153.757815  8.542101  0.019932   \n",
       "2             2.000000   4.754888    0.500000    2.377444  0.132080  0.001585   \n",
       "3             6.754888  13.931569    1.333333   18.575425  1.031968  0.004644   \n",
       "4            17.509775  27.000000    1.000000   27.000000  1.500000  0.009000   \n",
       "..                 ...        ...         ...         ...       ...       ...   \n",
       "159           9.509775  31.019550    4.000000  124.078200  6.893233  0.010340   \n",
       "160          24.000000  57.058650    0.750000   42.793988  2.377444  0.019020   \n",
       "161           0.000000   2.000000    0.500000    1.000000  0.055556  0.000667   \n",
       "162           0.000000   2.000000    0.500000    1.000000  0.055556  0.000667   \n",
       "163          20.264663  28.529325    1.500000   42.793988  2.377444  0.009510   \n",
       "\n",
       "             MI  \n",
       "0     94.062602  \n",
       "1     86.970176  \n",
       "2     65.110353  \n",
       "3     96.412688  \n",
       "4     87.277819  \n",
       "..          ...  \n",
       "159   55.822181  \n",
       "160   45.813793  \n",
       "161   96.882486  \n",
       "162  100.000000  \n",
       "163   80.289730  \n",
       "\n",
       "[164 rows x 30 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.insert(3, \"model\", f\"llama3_0_shot_finetuned_smaller_LR_{epoch_num}_epoch\")\n",
    "df.insert(4, \"code\", all_generations)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9939024390243902, 0.6463414634146342)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"compiled\"].mean(), df[\"passed_tests\"].mean()\n",
    "# @1 = (0.9939024390243902, 0.6463414634146342)\n",
    "# @2 = (0.9939024390243902, 0.6707317073170732)\n",
    "# @3 = (0.9878048780487805, 0.6036585365853658)\n",
    "# @4 = (0.9939024390243902, 0.5792682926829268)\n",
    "# @5 = (0.9878048780487805, 0.5609756097560976)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9939024390243902, 0.6707317073170732)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"compiled\"].mean(), df[\"passed_tests\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, when everything looks good save the data. Will overwrite previously\n",
    "# saved data at this location. Be sure you want to do this!\n",
    "df.to_csv(RESULTS_PATH + f\"openai_humaneval_llama3_0_shot_finetuned_smaller_LR_{epoch_num}_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>task_id</th>\n",
       "      <th>model</th>\n",
       "      <th>code</th>\n",
       "      <th>result</th>\n",
       "      <th>compiled</th>\n",
       "      <th>passed_tests</th>\n",
       "      <th>avg_test_time</th>\n",
       "      <th>loc</th>\n",
       "      <th>...</th>\n",
       "      <th>N2</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>length</th>\n",
       "      <th>calculated_length</th>\n",
       "      <th>volume</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>effort</th>\n",
       "      <th>time</th>\n",
       "      <th>bugs</th>\n",
       "      <th>MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "      <td>failed:</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.509775</td>\n",
       "      <td>39.863137</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>106.301699</td>\n",
       "      <td>5.905650</td>\n",
       "      <td>0.013288</td>\n",
       "      <td>94.062602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td></td>\n",
       "      <td>failed: name 'separate_paren_groups' is not de...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td></td>\n",
       "      <td>failed: name 'parse_nested_parens' is not defined</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td>from typing import List, Tuple\\n\\ndef sum_prod...</td>\n",
       "      <td>failed: invalid syntax (&lt;string&gt;, line 11)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td>from typing import List\\n\\ndef rolling_max(num...</td>\n",
       "      <td>failed: list index out of range</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>148</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td>def bf(planet1, planet2):\\n    '''\\n    There ...</td>\n",
       "      <td>failed: First test error: 3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.138965</td>\n",
       "      <td>106.605938</td>\n",
       "      <td>5.277778</td>\n",
       "      <td>562.642450</td>\n",
       "      <td>31.257914</td>\n",
       "      <td>0.035535</td>\n",
       "      <td>78.745224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>152</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td></td>\n",
       "      <td>failed: name 'compare' is not defined</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>155</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td>def even_odd_count(num):\\n    \"\"\"Given an inte...</td>\n",
       "      <td>failed: '(' was never closed (&lt;string&gt;, line 9)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>158</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td>def find_max(words):\\n    \"\"\"Write a function ...</td>\n",
       "      <td>failed: t2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>openai_humaneval</td>\n",
       "      <td>test</td>\n",
       "      <td>161</td>\n",
       "      <td>llama3_0_shot_finetuned_smaller_LR_5_epoch</td>\n",
       "      <td></td>\n",
       "      <td>failed: name 'solve' is not defined</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset split  task_id  \\\n",
       "0    openai_humaneval  test        0   \n",
       "1    openai_humaneval  test        1   \n",
       "6    openai_humaneval  test        6   \n",
       "8    openai_humaneval  test        8   \n",
       "9    openai_humaneval  test        9   \n",
       "..                ...   ...      ...   \n",
       "148  openai_humaneval  test      148   \n",
       "152  openai_humaneval  test      152   \n",
       "155  openai_humaneval  test      155   \n",
       "158  openai_humaneval  test      158   \n",
       "161  openai_humaneval  test      161   \n",
       "\n",
       "                                          model  \\\n",
       "0    llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "1    llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "6    llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "8    llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "9    llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "..                                          ...   \n",
       "148  llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "152  llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "155  llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "158  llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "161  llama3_0_shot_finetuned_smaller_LR_5_epoch   \n",
       "\n",
       "                                                  code  \\\n",
       "0    from typing import List\\n\\ndef has_close_eleme...   \n",
       "1                                                        \n",
       "6                                                        \n",
       "8    from typing import List, Tuple\\n\\ndef sum_prod...   \n",
       "9    from typing import List\\n\\ndef rolling_max(num...   \n",
       "..                                                 ...   \n",
       "148  def bf(planet1, planet2):\\n    '''\\n    There ...   \n",
       "152                                                      \n",
       "155  def even_odd_count(num):\\n    \"\"\"Given an inte...   \n",
       "158  def find_max(words):\\n    \"\"\"Write a function ...   \n",
       "161                                                      \n",
       "\n",
       "                                                result  compiled  \\\n",
       "0                                             failed:       True   \n",
       "1    failed: name 'separate_paren_groups' is not de...      True   \n",
       "6    failed: name 'parse_nested_parens' is not defined      True   \n",
       "8           failed: invalid syntax (<string>, line 11)     False   \n",
       "9                      failed: list index out of range      True   \n",
       "..                                                 ...       ...   \n",
       "148                        failed: First test error: 3      True   \n",
       "152              failed: name 'compare' is not defined      True   \n",
       "155    failed: '(' was never closed (<string>, line 9)     False   \n",
       "158                                         failed: t2      True   \n",
       "161                failed: name 'solve' is not defined      True   \n",
       "\n",
       "     passed_tests  avg_test_time   loc  ...    N2  vocabulary  length  \\\n",
       "0           False            NaN  16.0  ...   8.0        10.0    12.0   \n",
       "1           False            NaN   NaN  ...   NaN         NaN     NaN   \n",
       "6           False            NaN   NaN  ...   NaN         NaN     NaN   \n",
       "8           False            NaN   NaN  ...   NaN         NaN     NaN   \n",
       "9           False            NaN  16.0  ...   0.0         0.0     0.0   \n",
       "..            ...            ...   ...  ...   ...         ...     ...   \n",
       "148         False            NaN  25.0  ...  19.0        14.0    28.0   \n",
       "152         False            NaN   NaN  ...   NaN         NaN     NaN   \n",
       "155         False            NaN   NaN  ...   NaN         NaN     NaN   \n",
       "158         False            NaN  11.0  ...   0.0         0.0     0.0   \n",
       "161         False            NaN   NaN  ...   NaN         NaN     NaN   \n",
       "\n",
       "     calculated_length      volume  difficulty      effort       time  \\\n",
       "0            23.509775   39.863137    2.666667  106.301699   5.905650   \n",
       "1                  NaN         NaN         NaN         NaN        NaN   \n",
       "6                  NaN         NaN         NaN         NaN        NaN   \n",
       "8                  NaN         NaN         NaN         NaN        NaN   \n",
       "9             0.000000    0.000000    0.000000    0.000000   0.000000   \n",
       "..                 ...         ...         ...         ...        ...   \n",
       "148          40.138965  106.605938    5.277778  562.642450  31.257914   \n",
       "152                NaN         NaN         NaN         NaN        NaN   \n",
       "155                NaN         NaN         NaN         NaN        NaN   \n",
       "158           0.000000    0.000000    0.000000    0.000000   0.000000   \n",
       "161                NaN         NaN         NaN         NaN        NaN   \n",
       "\n",
       "         bugs          MI  \n",
       "0    0.013288   94.062602  \n",
       "1         NaN         NaN  \n",
       "6         NaN         NaN  \n",
       "8         NaN         NaN  \n",
       "9    0.000000  100.000000  \n",
       "..        ...         ...  \n",
       "148  0.035535   78.745224  \n",
       "152       NaN         NaN  \n",
       "155       NaN         NaN  \n",
       "158  0.000000  100.000000  \n",
       "161       NaN         NaN  \n",
       "\n",
       "[72 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"not passed_tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
